{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a9c157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 21:26:49.789932: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da34c599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 21:26:54.050441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x10803d8b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Initializer\n",
    "keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d7eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = gym.make('CartPole-v1')\n",
    "env = gym.make(\n",
    "            id=\"CartPole-v1\",  # Choose one of the existing environments\n",
    "            render_mode=\"rgb_array\",  # The set of supported modes varies per environment. (And some third-party environments may not support rendering at all.)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41920d",
   "metadata": {},
   "source": [
    "Action Space is a [Discrete](https://gymnasium.farama.org/api/spaces/fundamental/#gymnasium.spaces.Discrete) type\n",
    "A space consisting of finitely many elements.\n",
    "In CartPole-v1, it has two actions: left or right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65ca180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gymnasium.spaces.discrete.Discrete'>\n",
      "Action space size: 2\n",
      "Action space start value: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(env.action_space))\n",
    "print(f\"Action space size: {env.action_space.n}\")\n",
    "print(f\"Action space start value: {env.action_space.start}\")\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81095b1a",
   "metadata": {},
   "source": [
    "Observation space is a 4 dimension state: \n",
    "- Cart Position\n",
    "- Cart Velocity\n",
    "- Pole Angle\n",
    "- Pole Velocity at tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af424be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gymnasium.spaces.box.Box'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(env.observation_space))\n",
    "# print(f\"Action space size: {env.observation_space.n}\")\n",
    "# print(f\"Action space start value: {env.observation_space.start}\")\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e9324d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9f9058",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation,_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679dfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state, reward, terminated, truncated, info = env.step(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df866624",
   "metadata": {},
   "source": [
    "### Create CartPole environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9fac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from q_learning_lab.domain.models.cart_pole_v1_models import Params as Cart_Pole_Params\n",
    "from pathlib import Path\n",
    "params = Cart_Pole_Params(\n",
    "            total_episodes=2000,\n",
    "            n_max_steps=100,\n",
    "            learning_rate=0.7, # learning rate alpha\n",
    "            gamma=0.618, # discount rate\n",
    "            epsilon=0.1,\n",
    "            savefig_folder=Path(\"_static/img/tutorials/\"),\n",
    "            savemodel_folder=Path(\"_static/model/tutorials/\"),\n",
    "            start_epsilon=1.0,  # Starting exploration probability\n",
    "            min_epsilon=0.05,  # Minimum exploration probability\n",
    "            decay_rate=0.001,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef39076",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m env \u001b[39m=\u001b[39m create_execute_environment(arena\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCartPole-v1\u001b[39m\u001b[39m\"\u001b[39m, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m      7\u001b[0m dnn_structure \u001b[39m=\u001b[39m get_dnn_structure(\n\u001b[1;32m      8\u001b[0m             input_dim\u001b[39m=\u001b[39menv\u001b[39m.\u001b[39mobservation_space_dim,\n\u001b[1;32m      9\u001b[0m             output_dim\u001b[39m=\u001b[39menv\u001b[39m.\u001b[39maction_space_dim,\n\u001b[1;32m     10\u001b[0m         )\n\u001b[0;32m---> 11\u001b[0m deepagent_dict \u001b[39m=\u001b[39m Reinforcement_DeepLearning\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     12\u001b[0m             env\u001b[39m=\u001b[39;49menv,\n\u001b[1;32m     13\u001b[0m             params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m     14\u001b[0m             dnn_structure\u001b[39m=\u001b[39;49mdnn_structure,\n\u001b[1;32m     15\u001b[0m             is_verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     16\u001b[0m         )\n\u001b[1;32m     17\u001b[0m model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     18\u001b[0m             params\u001b[39m.\u001b[39msavemodel_folder, \u001b[39m\"\u001b[39m\u001b[39minteractive\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCartPole-v1-main\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m         )\n\u001b[1;32m     20\u001b[0m deepagent_dict[\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msave_agent(path\u001b[39m=\u001b[39mmodel_path)\n",
      "File \u001b[0;32m~/sandbox/algo_trading/gym/q_learning_lab/src/q_learning_lab/domain/deep_q_learn.py:280\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(env, params, dnn_structure, is_verbose)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mfor\u001b[39;00m episode \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(total_episodes):\n\u001b[1;32m    279\u001b[0m     total_training_rewards: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 280\u001b[0m     state, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    281\u001b[0m     terminated: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m terminated:\n",
      "File \u001b[0;32m~/sandbox/algo_trading/gym/q_learning_lab/src/q_learning_lab/port/environment.py:18\u001b[0m, in \u001b[0;36mExecute_Environment.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[0;32m~/sandbox/algo_trading/gym/q_learning_lab/src/q_learning_lab/adapter/gym/gym_environment.py:79\u001b[0m, in \u001b[0;36mCart_Pole_v1_Environment.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m plt\u001b[39m.\u001b[39mimshow(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mrender())  \u001b[39m# render current state and pass to pyplot\u001b[39;00m\n\u001b[1;32m     78\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m\"\u001b[39m\u001b[39moff\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m display\u001b[39m.\u001b[39;49mdisplay(plt\u001b[39m.\u001b[39;49mgcf())  \u001b[39m# get current figure and display\u001b[39;00m\n\u001b[1;32m     80\u001b[0m display\u001b[39m.\u001b[39mclear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[39m=\u001b[39mobj, metadata\u001b[39m=\u001b[39mmetadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39;49m(obj, include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[39m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/IPython/core/formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    177\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[1;32m    180\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/IPython/core/formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    224\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    341\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/backend_bases.py:2295\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2289\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[1;32m   2290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[1;32m   2291\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   2292\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m   2293\u001b[0m     )\n\u001b[1;32m   2294\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2295\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m   2297\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2298\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/artist.py:73\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 73\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     75\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/figure.py:2837\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2834\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   2836\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 2837\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   2838\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   2840\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   2841\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/axes/_base.py:3091\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3088\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   3089\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[0;32m-> 3091\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3092\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3094\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3095\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/image.py:646\u001b[0m, in \u001b[0;36m_ImageBase.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m         renderer\u001b[39m.\u001b[39mdraw_image(gc, l, b, im, trans)\n\u001b[1;32m    645\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 646\u001b[0m     im, l, b, trans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_image(\n\u001b[1;32m    647\u001b[0m         renderer, renderer\u001b[39m.\u001b[39;49mget_image_magnification())\n\u001b[1;32m    648\u001b[0m     \u001b[39mif\u001b[39;00m im \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m         renderer\u001b[39m.\u001b[39mdraw_image(gc, l, b, im)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/image.py:956\u001b[0m, in \u001b[0;36mAxesImage.make_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    953\u001b[0m transformed_bbox \u001b[39m=\u001b[39m TransformedBbox(bbox, trans)\n\u001b[1;32m    954\u001b[0m clip \u001b[39m=\u001b[39m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_clip_box() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mbbox) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_clip_on()\n\u001b[1;32m    955\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mbbox)\n\u001b[0;32m--> 956\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_image(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_A, bbox, transformed_bbox, clip,\n\u001b[1;32m    957\u001b[0m                         magnification, unsampled\u001b[39m=\u001b[39;49munsampled)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/image.py:557\u001b[0m, in \u001b[0;36m_ImageBase._make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    554\u001b[0m     alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_scalar_alpha()\n\u001b[1;32m    555\u001b[0m     output_alpha \u001b[39m=\u001b[39m _resample(  \u001b[39m# resample alpha channel\u001b[39;00m\n\u001b[1;32m    556\u001b[0m         \u001b[39mself\u001b[39m, A[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m3\u001b[39m], out_shape, t, alpha\u001b[39m=\u001b[39malpha)\n\u001b[0;32m--> 557\u001b[0m     output \u001b[39m=\u001b[39m _resample(  \u001b[39m# resample rgb channels\u001b[39;49;00m\n\u001b[1;32m    558\u001b[0m         \u001b[39mself\u001b[39;49m, _rgb_to_rgba(A[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, :\u001b[39m3\u001b[39;49m]), out_shape, t, alpha\u001b[39m=\u001b[39;49malpha)\n\u001b[1;32m    559\u001b[0m     output[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m output_alpha  \u001b[39m# recombine rgb and alpha\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[39m# at this point output is either a 2D array of normed data\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[39m# (of int or float)\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# or an RGBA array of re-sampled input\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/q-learning-lab/lib/python3.9/site-packages/matplotlib/image.py:193\u001b[0m, in \u001b[0;36m_resample\u001b[0;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m resample \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     resample \u001b[39m=\u001b[39m image_obj\u001b[39m.\u001b[39mget_resample()\n\u001b[0;32m--> 193\u001b[0m _image\u001b[39m.\u001b[39;49mresample(data, out, transform,\n\u001b[1;32m    194\u001b[0m                 _interpd_[interpolation],\n\u001b[1;32m    195\u001b[0m                 resample,\n\u001b[1;32m    196\u001b[0m                 alpha,\n\u001b[1;32m    197\u001b[0m                 image_obj\u001b[39m.\u001b[39;49mget_filternorm(),\n\u001b[1;32m    198\u001b[0m                 image_obj\u001b[39m.\u001b[39;49mget_filterrad())\n\u001b[1;32m    199\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from q_learning_lab.port.environment import create_execute_environment\n",
    "from q_learning_lab.domain.models.cart_pole_v1_models import get_dnn_structure\n",
    "from q_learning_lab.domain.deep_q_learn import Reinforcement_DeepLearning\n",
    "import os\n",
    "# Create the environment\n",
    "env = create_execute_environment(arena=\"CartPole-v1\", params=params)\n",
    "dnn_structure = get_dnn_structure(\n",
    "            input_dim=env.observation_space_dim,\n",
    "            output_dim=env.action_space_dim,\n",
    "        )\n",
    "deepagent_dict = Reinforcement_DeepLearning.train(\n",
    "            env=env,\n",
    "            params=params,\n",
    "            dnn_structure=dnn_structure,\n",
    "            is_verbose=True,\n",
    "            model_name=\"CartPole-v1-interactive\",\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:q-learning-lab] *",
   "language": "python",
   "name": "conda-env-q-learning-lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
